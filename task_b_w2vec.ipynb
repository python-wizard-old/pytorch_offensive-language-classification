{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sprawdzanie czy w systemie jest karta graficzna Nvidia - CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_av = torch.cuda.is_available()\n",
    "cuda_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID urzdzenia CUDA: 0\n",
      "Nazwa urzdzenia CUDA: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "if cuda_av:\n",
    "    cuda_id = torch.cuda.current_device()\n",
    "    print(f'ID urzdzenia CUDA: {cuda_id}')\n",
    "    print(f\"Nazwa urzdzenia CUDA: {torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tworzenie kodu uniwersalnego: dla CUDA i CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## adowanie danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data/olid-training-v1.0.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              tweet subtask_a  \\\n0  86426  @USER She should ask a few native Americans wh...       OFF   \n1  90194  @USER @USER Go home youre drunk!!! @USER #MAG...       OFF   \n2  16820  Amazon is investigating Chinese employees who ...       NOT   \n3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n\n  subtask_b subtask_c  \n0       UNT       NaN  \n1       TIN       IND  \n2       NaN       NaN  \n3       UNT       NaN  \n4       NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>subtask_b</th>\n      <th>subtask_c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>86426</td>\n      <td>@USER She should ask a few native Americans wh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90194</td>\n      <td>@USER @USER Go home youre drunk!!! @USER #MAG...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16820</td>\n      <td>Amazon is investigating Chinese employees who ...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>62688</td>\n      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43605</td>\n      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets = tweets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets = tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usuwanie tweetow gdzie kulumna subtask_b jest nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "13240"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna(subset=['subtask_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4400"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenizacja, lematyzacja, us贸wanie pewnych s贸w\n",
    "liczenie najdu偶szego przetworzonego tweeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dodawanie kolumny z tokenami\n",
    "tweets['tokens'] = tweets['tweet'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              tweet subtask_a  \\\n0  86426  @USER She should ask a few native Americans wh...       OFF   \n1  90194  @USER @USER Go home youre drunk!!! @USER #MAG...       OFF   \n3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n5  97670                  @USER Liberals are all Kookoo !!!       OFF   \n6  77444                   @USER @USER Oh noes! Tough shit.       OFF   \n\n  subtask_b subtask_c                                             tokens  \n0       UNT       NaN  (@USER, She, should, ask, a, few, native, Amer...  \n1       TIN       IND  (@USER, @USER, Go, home, you, re, drunk, !, !...  \n3       UNT       NaN  (@USER, Someone, should'veTaken, \", this, piec...  \n5       TIN       OTH       (@USER, Liberals, are, all, Kookoo, !, !, !)  \n6       UNT       NaN        (@USER, @USER, Oh, noes, !, Tough, shit, .)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>subtask_b</th>\n      <th>subtask_c</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>86426</td>\n      <td>@USER She should ask a few native Americans wh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, She, should, ask, a, few, native, Amer...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90194</td>\n      <td>@USER @USER Go home youre drunk!!! @USER #MAG...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, @USER, Go, home, you, re, drunk, !, !...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>62688</td>\n      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, Someone, should'veTaken, \", this, piec...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>97670</td>\n      <td>@USER Liberals are all Kookoo !!!</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>OTH</td>\n      <td>(@USER, Liberals, are, all, Kookoo, !, !, !)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>77444</td>\n      <td>@USER @USER Oh noes! Tough shit.</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, @USER, Oh, noes, !, Tough, shit, .)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dodawanie kolumny z lematami za pomoca funkcji lambda - przy tym usuwanie:\n",
    "# odwolan do wczesniejszych tweetow (zawiera @)\n",
    "# - slowa url (czyli adresy stron inernetowych kt贸re w danych wejciowych maj URL zamiast adreasu.\n",
    "# # - hasztag贸w; przyimk贸w i innych czstych s贸w (stop words) oraz znak贸w interpunkcyjnych.\n",
    "# spacji ' ', '  ', '   '\n",
    "\n",
    "# emotikony zostawiam - uwa偶am, 偶e te偶 nios znaczenie\n",
    "\n",
    "tweets['lemmas'] = tweets['tokens'].apply\\\n",
    "    (lambda list_tokens : [token.lemma_.strip() for token in list_tokens if ('@' not in token.lemma_ \\\n",
    "                                                                     and '#' not in token.lemma_ and 'url' not in token.lemma_ \\\n",
    "                                                                     and not token.is_stop and not token.is_punct and token.lemma_ != ' ' \\\n",
    "                                                                     and token.lemma_ != '  ' and token.lemma_ != '   '\n",
    "                                                                     and token.lemma_ != '    ' and token.lemma_.strip() != '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          id                                              tweet subtask_a  \\\n0      86426  @USER She should ask a few native Americans wh...       OFF   \n1      90194  @USER @USER Go home youre drunk!!! @USER #MAG...       OFF   \n3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n5      97670                  @USER Liberals are all Kookoo !!!       OFF   \n6      77444                   @USER @USER Oh noes! Tough shit.       OFF   \n...      ...                                                ...       ...   \n13223  63482  @USER is advocating for conduct within bounds ...       OFF   \n13227  87416  @USER @USER @USER @USER Liars like the Antifa ...       OFF   \n13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n13238  27429                                        @USER Pussy       OFF   \n\n      subtask_b subtask_c                                             tokens  \\\n0           UNT       NaN  (@USER, She, should, ask, a, few, native, Amer...   \n1           TIN       IND  (@USER, @USER, Go, home, you, re, drunk, !, !...   \n3           UNT       NaN  (@USER, Someone, should'veTaken, \", this, piec...   \n5           TIN       OTH       (@USER, Liberals, are, all, Kookoo, !, !, !)   \n6           UNT       NaN        (@USER, @USER, Oh, noes, !, Tough, shit, .)   \n...         ...       ...                                                ...   \n13223       TIN       GRP  (@USER, is, advocating, for, conduct, within, ...   \n13227       TIN       GRP  (@USER, @USER, @USER, @USER, Liars, like, the,...   \n13235       TIN       IND  (@USER, Sometimes, I, get, strong, vibes, from...   \n13237       TIN       OTH  (@USER, And, why, report, this, garbage, .,  ,...   \n13238       UNT       NaN                                     (@USER, Pussy)   \n\n                                                  lemmas  \n0                               [ask, native, Americans]  \n1             [home, drunk, MAGA, Trump2020, , , , ]  \n3              [should'vetaken, piece, shit, volcano, ]  \n5                                      [liberal, Kookoo]  \n6                                  [oh, no, tough, shit]  \n...                                                  ...  \n13223  [advocate, conduct, bound, Human, Rights, terr...  \n13227     [liar, like, Antifa, twin, vigorously, defend]  \n13235  [strong, vibe, people, man, vibe, ten, million...  \n13237                            [report, garbage, crap]  \n13238                                            [Pussy]  \n\n[4400 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>subtask_b</th>\n      <th>subtask_c</th>\n      <th>tokens</th>\n      <th>lemmas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>86426</td>\n      <td>@USER She should ask a few native Americans wh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, She, should, ask, a, few, native, Amer...</td>\n      <td>[ask, native, Americans]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90194</td>\n      <td>@USER @USER Go home youre drunk!!! @USER #MAG...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, @USER, Go, home, you, re, drunk, !, !...</td>\n      <td>[home, drunk, MAGA, Trump2020, , , , ]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>62688</td>\n      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, Someone, should'veTaken, \", this, piec...</td>\n      <td>[should'vetaken, piece, shit, volcano, ]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>97670</td>\n      <td>@USER Liberals are all Kookoo !!!</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>OTH</td>\n      <td>(@USER, Liberals, are, all, Kookoo, !, !, !)</td>\n      <td>[liberal, Kookoo]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>77444</td>\n      <td>@USER @USER Oh noes! Tough shit.</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, @USER, Oh, noes, !, Tough, shit, .)</td>\n      <td>[oh, no, tough, shit]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13223</th>\n      <td>63482</td>\n      <td>@USER is advocating for conduct within bounds ...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>GRP</td>\n      <td>(@USER, is, advocating, for, conduct, within, ...</td>\n      <td>[advocate, conduct, bound, Human, Rights, terr...</td>\n    </tr>\n    <tr>\n      <th>13227</th>\n      <td>87416</td>\n      <td>@USER @USER @USER @USER Liars like the Antifa ...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>GRP</td>\n      <td>(@USER, @USER, @USER, @USER, Liars, like, the,...</td>\n      <td>[liar, like, Antifa, twin, vigorously, defend]</td>\n    </tr>\n    <tr>\n      <th>13235</th>\n      <td>95338</td>\n      <td>@USER Sometimes I get strong vibes from people...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, Sometimes, I, get, strong, vibes, from...</td>\n      <td>[strong, vibe, people, man, vibe, ten, million...</td>\n    </tr>\n    <tr>\n      <th>13237</th>\n      <td>82921</td>\n      <td>@USER And why report this garbage.  We don't g...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>OTH</td>\n      <td>(@USER, And, why, report, this, garbage, .,  ,...</td>\n      <td>[report, garbage, crap]</td>\n    </tr>\n    <tr>\n      <th>13238</th>\n      <td>27429</td>\n      <td>@USER Pussy</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, Pussy)</td>\n      <td>[Pussy]</td>\n    </tr>\n  </tbody>\n</table>\n<p>4400 rows  7 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for index, row in tweets.iterrows():\n",
    "#     for word in row['lemmas']:\n",
    "#         if word == '':\n",
    "#             print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets.iloc[499, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if tweets.iloc[500, 6][0] == '':\n",
    "#     print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets.iloc[500, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweets.loc[:3,'lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       id                                              tweet subtask_a  \\\n7   52415  @USER was literally just talking about this lo...       OFF   \n9   13384  @USER Canada doesnt need another CUCK! We alr...       OFF   \n12  28414  @USER you are a lying corrupt traitor!!! Nobod...       OFF   \n19  28195  @USER @USER @USER gun control! That is all the...       OFF   \n20  56117  @USER @USER @USER @USER LOL!!!   Throwing the ...       OFF   \n22  12681  @USER @USER Kind of like when conservatives wa...       OFF   \n23  82904  @USER @USER Da fuck is going on people?   Ther...       OFF   \n25  77665  @USER Tbh these days i just don't like people ...       OFF   \n29  25440  @USER @USER @USER She?  To whom are you referr...       OFF   \n32  12609  The only thing the Democrats have is lying and...       OFF   \n36  12108  @USER @USER @USER @USER @USER @USER @USER @USE...       OFF   \n37  14726  @USER @USER @USER That's expected if you placa...       OFF   \n54  84102  4 out of 10 British people are basically full-...       OFF   \n57  98992                                     @USER Fuck off       OFF   \n59  33853  @USER @USER The prison system is so fucked.  W...       OFF   \n\n   subtask_b subtask_c                                             tokens  \\\n7        TIN       GRP  (@USER, was, literally, just, talking, about, ...   \n9        TIN       IND  (@USER, Canada, does, nt, need, another, CUCK...   \n12       TIN       IND  (@USER, you, are, a, lying, corrupt, traitor, ...   \n19       TIN       OTH  (@USER, @USER, @USER, gun, control, !, That, i...   \n20       TIN       IND  (@USER, @USER, @USER, @USER, LOL, !, !, !,   ,...   \n22       TIN       GRP  (@USER, @USER, Kind, of, like, when, conservat...   \n23       TIN       GRP  (@USER, @USER, Da, fuck, is, going, on, people...   \n25       TIN       IND  (@USER, Tbh, these, days, i, just, do, n't, li...   \n29       UNT       NaN  (@USER, @USER, @USER, She, ?,  , To, whom, are...   \n32       TIN       GRP  (The, only, thing, the, Democrats, have, is, l...   \n36       TIN       IND  (@USER, @USER, @USER, @USER, @USER, @USER, @US...   \n37       TIN       GRP  (@USER, @USER, @USER, That, 's, expected, if, ...   \n54       TIN       GRP  (4, out, of, 10, British, people, are, basical...   \n57       TIN       IND                                 (@USER, Fuck, off)   \n59       TIN       OTH  (@USER, @USER, The, prison, system, is, so, fu...   \n\n                                               lemmas  \n7   [literally, talk, lol, mass, shooting, like, s...  \n9   [Canada, need, CUCK, LooneyLeft, Liberals, f**...  \n12  [lie, corrupt, traitor, want, hear, anymore, l...  \n19                           [gun, control, kid, ask]  \n20  [LOL, throw, BULLSHIT, Flag, nonsense, putupor...  \n22  [kind, like, conservative, wanna, associate, l...  \n23  [Da, fuck, go, people, man, room, woman, room,...  \n25  [tbh, day, like, people, general, connect, peo...  \n29  [refer, Hillary, know, tiresome, Bernie, suppo...  \n32  [thing, Democrats, lie, stall, stop, Trump, Pr...  \n36  [smart, think, Gen, Flynn, sentencing, keep, r...  \n37  [expect, placate, violent, leftist, terrorist,...  \n54  [4, 10, british, people, basically, racist, 4,...  \n57                                             [fuck]  \n59  [prison, system, fucked, get, away, potentiall...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>subtask_b</th>\n      <th>subtask_c</th>\n      <th>tokens</th>\n      <th>lemmas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>52415</td>\n      <td>@USER was literally just talking about this lo...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>GRP</td>\n      <td>(@USER, was, literally, just, talking, about, ...</td>\n      <td>[literally, talk, lol, mass, shooting, like, s...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13384</td>\n      <td>@USER Canada doesnt need another CUCK! We alr...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, Canada, does, nt, need, another, CUCK...</td>\n      <td>[Canada, need, CUCK, LooneyLeft, Liberals, f**...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>28414</td>\n      <td>@USER you are a lying corrupt traitor!!! Nobod...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, you, are, a, lying, corrupt, traitor, ...</td>\n      <td>[lie, corrupt, traitor, want, hear, anymore, l...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>28195</td>\n      <td>@USER @USER @USER gun control! That is all the...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>OTH</td>\n      <td>(@USER, @USER, @USER, gun, control, !, That, i...</td>\n      <td>[gun, control, kid, ask]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>56117</td>\n      <td>@USER @USER @USER @USER LOL!!!   Throwing the ...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, @USER, @USER, @USER, LOL, !, !, !,   ,...</td>\n      <td>[LOL, throw, BULLSHIT, Flag, nonsense, putupor...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>12681</td>\n      <td>@USER @USER Kind of like when conservatives wa...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>GRP</td>\n      <td>(@USER, @USER, Kind, of, like, when, conservat...</td>\n      <td>[kind, like, conservative, wanna, associate, l...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>82904</td>\n      <td>@USER @USER Da fuck is going on people?   Ther...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>GRP</td>\n      <td>(@USER, @USER, Da, fuck, is, going, on, people...</td>\n      <td>[Da, fuck, go, people, man, room, woman, room,...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>77665</td>\n      <td>@USER Tbh these days i just don't like people ...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, Tbh, these, days, i, just, do, n't, li...</td>\n      <td>[tbh, day, like, people, general, connect, peo...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>25440</td>\n      <td>@USER @USER @USER She?  To whom are you referr...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, @USER, @USER, She, ?,  , To, whom, are...</td>\n      <td>[refer, Hillary, know, tiresome, Bernie, suppo...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>12609</td>\n      <td>The only thing the Democrats have is lying and...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>GRP</td>\n      <td>(The, only, thing, the, Democrats, have, is, l...</td>\n      <td>[thing, Democrats, lie, stall, stop, Trump, Pr...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>12108</td>\n      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, @USER, @USER, @USER, @USER, @USER, @US...</td>\n      <td>[smart, think, Gen, Flynn, sentencing, keep, r...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>14726</td>\n      <td>@USER @USER @USER That's expected if you placa...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>GRP</td>\n      <td>(@USER, @USER, @USER, That, 's, expected, if, ...</td>\n      <td>[expect, placate, violent, leftist, terrorist,...</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>84102</td>\n      <td>4 out of 10 British people are basically full-...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>GRP</td>\n      <td>(4, out, of, 10, British, people, are, basical...</td>\n      <td>[4, 10, british, people, basically, racist, 4,...</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>98992</td>\n      <td>@USER Fuck off</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, Fuck, off)</td>\n      <td>[fuck]</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>33853</td>\n      <td>@USER @USER The prison system is so fucked.  W...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>OTH</td>\n      <td>(@USER, @USER, The, prison, system, is, so, fu...</td>\n      <td>[prison, system, fucked, get, away, potentiall...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[5:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['length_lemmas'] = tweets['lemmas'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0     3\n1     8\n3     5\n5     2\n6     4\n7    16\n9    10\nName: length_lemmas, dtype: int64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[:10, 'length_lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_length_tweet = max(tweets['length_lemmas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## adowanie danych testowych(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_level_b = pd.read_csv('data/testset-levelb.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_level_b = pd.read_csv('data/labels-levelb.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_level_b = labels_level_b.rename(columns={0:'id', 1:'subtask_b'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_b = pd.merge(test_level_b, labels_level_b, on = \"id\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              tweet subtask_b\n0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       TIN\n1  60133  #NoPasaran: Unity demo to oppose the far-right...       TIN\n2  83681           . . . What the fuck did he do this time?       TIN\n3  65507  @USER Do you get the feeling he is kissing @US...       TIN\n4  12588                        @USER Nigga ware da hits at       UNT",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15923</td>\n      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n      <td>TIN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>60133</td>\n      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n      <td>TIN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>83681</td>\n      <td>. . . What the fuck did he do this time?</td>\n      <td>TIN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>65507</td>\n      <td>@USER Do you get the feeling he is kissing @US...</td>\n      <td>TIN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12588</td>\n      <td>@USER Nigga ware da hits at</td>\n      <td>UNT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "240"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_b = test_b.dropna(subset=['subtask_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "240"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opracowanie danych testowych (cz a)\n",
    "Takie same modyfikacje jak dla danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_b['tokens'] = test_b['tweet'].apply(nlp)\n",
    "test_b['lemmas'] = test_b['tokens'].apply \\\n",
    "    (lambda list_tokens : [token.lemma_.strip() for token in list_tokens if ('@' not in token.lemma_\n",
    "                                                                             and '#' not in token.lemma_ and 'url' not in token.lemma_\n",
    "                                                                             and not token.is_stop and not token.is_punct and token.lemma_ != ' '\n",
    "                                                                             and token.lemma_ != '  ' and token.lemma_ != '   '\n",
    "                                                                             and token.lemma_ != '    ' and token.lemma_.strip() != '')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_b['length_lemmas'] = test_b['lemmas'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "40"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_b['length_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              tweet subtask_b  \\\n0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       TIN   \n1  60133  #NoPasaran: Unity demo to oppose the far-right...       TIN   \n2  83681           . . . What the fuck did he do this time?       TIN   \n3  65507  @USER Do you get the feeling he is kissing @US...       TIN   \n4  12588                        @USER Nigga ware da hits at       UNT   \n\n                                              tokens  \\\n0  (#, WhoIsQ, #, WheresTheServer, #, DumpNike, #...   \n1  (#, NoPasaran, :, Unity, demo, to, oppose, the...   \n2  (., ., ., What, the, fuck, did, he, do, this, ...   \n3  (@USER, Do, you, get, the, feeling, he, is, ki...   \n4                 (@USER, Nigga, ware, da, hits, at)   \n\n                                              lemmas  length_lemmas  \n0  [WhoIsQ, wherestheserver, DumpNike, DECLASFISA...             24  \n1  [NoPasaran, unity, demo, oppose, far, right, L...              9  \n2                                       [fuck, time]              2  \n3                  [feeling, kiss, humiliate, later]              4  \n4                             [Nigga, ware, da, hit]              4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_b</th>\n      <th>tokens</th>\n      <th>lemmas</th>\n      <th>length_lemmas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15923</td>\n      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n      <td>TIN</td>\n      <td>(#, WhoIsQ, #, WheresTheServer, #, DumpNike, #...</td>\n      <td>[WhoIsQ, wherestheserver, DumpNike, DECLASFISA...</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>60133</td>\n      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n      <td>TIN</td>\n      <td>(#, NoPasaran, :, Unity, demo, to, oppose, the...</td>\n      <td>[NoPasaran, unity, demo, oppose, far, right, L...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>83681</td>\n      <td>. . . What the fuck did he do this time?</td>\n      <td>TIN</td>\n      <td>(., ., ., What, the, fuck, did, he, do, this, ...</td>\n      <td>[fuck, time]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>65507</td>\n      <td>@USER Do you get the feeling he is kissing @US...</td>\n      <td>TIN</td>\n      <td>(@USER, Do, you, get, the, feeling, he, is, ki...</td>\n      <td>[feeling, kiss, humiliate, later]</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12588</td>\n      <td>@USER Nigga ware da hits at</td>\n      <td>UNT</td>\n      <td>(@USER, Nigga, ware, da, hits, at)</td>\n      <td>[Nigga, ware, da, hit]</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "240"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_length_tweet_test = max(test_b['length_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "40"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_tweet_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Maksymalna dugo wektora z lematami z tweet贸w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_width = max(max_length_tweet, max_length_tweet_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Funkcje do przekszacania danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_words_to_numbers(lemmas_series, dict_ = dict()):\n",
    "    # dict_ = dict()\n",
    "    for row in lemmas_series:\n",
    "        for lemma in row:\n",
    "            if lemma not in dict_:\n",
    "                dict_[lemma] = len(dict_) + 1\n",
    "\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lemmas_to_numbers(row, max_list_lemmas, dict_):\n",
    "    list_numbers = []\n",
    "    for i in range(max_list_lemmas - len(row)):\n",
    "        list_numbers.append(0)\n",
    "\n",
    "    for lemma in row:\n",
    "        list_numbers.append(dict_[lemma])\n",
    "\n",
    "    array_numbers = np.array(list_numbers, dtype=np.int32)\n",
    "    return array_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Powr贸t do opracowywania danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_lemmas = convert_words_to_numbers(tweets['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['$',\n \"'em\",\n '+',\n '-Antifa',\n '-Awkward',\n '-Bill',\n '-GOP',\n '-Human',\n '-I',\n '-Illegal']"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict_lemmas)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# zamiana lematu na liczbe ze slownika ktory odpowiada danemu slowu\n",
    "tweets['numbers'] = tweets['lemmas'].apply(lambda row : lemmas_to_numbers(row, max_width, dict_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n5    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n6    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\nName: numbers, dtype: object"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['numbers'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# przypisywanie X_train kolumny numbers skonwertowanej na tablice numpy\n",
    "X_train = tweets['numbers'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# czenie wierszy tablic w jedn tablic 2D\n",
    "X_train = np.stack(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# konwertowanie tablicy 2d do tensora\n",
    "X_train = torch.FloatTensor(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ustawianie kolumn z etykietami na poszczeg贸lne zadania jako type kt贸re przechowuj kategorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = ['subtask_a', 'subtask_b', 'subtask_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    tweets[col] = tweets[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets['labels_b'] = tweets['subtask_b'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    1\n1    0\n3    1\n5    0\nName: labels_b, dtype: int8"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OFFENSIVE jest jako 1, a NOT OFFENSIVE jest jako 0\n",
    "tweets.loc[:5, 'labels_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          id                                              tweet subtask_a  \\\n0      86426  @USER She should ask a few native Americans wh...       OFF   \n1      90194  @USER @USER Go home youre drunk!!! @USER #MAG...       OFF   \n3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n5      97670                  @USER Liberals are all Kookoo !!!       OFF   \n6      77444                   @USER @USER Oh noes! Tough shit.       OFF   \n...      ...                                                ...       ...   \n13223  63482  @USER is advocating for conduct within bounds ...       OFF   \n13227  87416  @USER @USER @USER @USER Liars like the Antifa ...       OFF   \n13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n13238  27429                                        @USER Pussy       OFF   \n\n      subtask_b subtask_c                                             tokens  \\\n0           UNT       NaN  (@USER, She, should, ask, a, few, native, Amer...   \n1           TIN       IND  (@USER, @USER, Go, home, you, re, drunk, !, !...   \n3           UNT       NaN  (@USER, Someone, should'veTaken, \", this, piec...   \n5           TIN       OTH       (@USER, Liberals, are, all, Kookoo, !, !, !)   \n6           UNT       NaN        (@USER, @USER, Oh, noes, !, Tough, shit, .)   \n...         ...       ...                                                ...   \n13223       TIN       GRP  (@USER, is, advocating, for, conduct, within, ...   \n13227       TIN       GRP  (@USER, @USER, @USER, @USER, Liars, like, the,...   \n13235       TIN       IND  (@USER, Sometimes, I, get, strong, vibes, from...   \n13237       TIN       OTH  (@USER, And, why, report, this, garbage, .,  ,...   \n13238       UNT       NaN                                     (@USER, Pussy)   \n\n                                                  lemmas  length_lemmas  \\\n0                               [ask, native, Americans]              3   \n1             [home, drunk, MAGA, Trump2020, , , , ]              8   \n3              [should'vetaken, piece, shit, volcano, ]              5   \n5                                      [liberal, Kookoo]              2   \n6                                  [oh, no, tough, shit]              4   \n...                                                  ...            ...   \n13223  [advocate, conduct, bound, Human, Rights, terr...             23   \n13227     [liar, like, Antifa, twin, vigorously, defend]              6   \n13235  [strong, vibe, people, man, vibe, ten, million...             10   \n13237                            [report, garbage, crap]              3   \n13238                                            [Pussy]              1   \n\n                                                 numbers  labels_b  \n0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n5      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n6      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n...                                                  ...       ...  \n13223  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n13227  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n13235  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n13237  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  \n13238  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         1  \n\n[4400 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>subtask_b</th>\n      <th>subtask_c</th>\n      <th>tokens</th>\n      <th>lemmas</th>\n      <th>length_lemmas</th>\n      <th>numbers</th>\n      <th>labels_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>86426</td>\n      <td>@USER She should ask a few native Americans wh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, She, should, ask, a, few, native, Amer...</td>\n      <td>[ask, native, Americans]</td>\n      <td>3</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90194</td>\n      <td>@USER @USER Go home youre drunk!!! @USER #MAG...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, @USER, Go, home, you, re, drunk, !, !...</td>\n      <td>[home, drunk, MAGA, Trump2020, , , , ]</td>\n      <td>8</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>62688</td>\n      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, Someone, should'veTaken, \", this, piec...</td>\n      <td>[should'vetaken, piece, shit, volcano, ]</td>\n      <td>5</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>97670</td>\n      <td>@USER Liberals are all Kookoo !!!</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>OTH</td>\n      <td>(@USER, Liberals, are, all, Kookoo, !, !, !)</td>\n      <td>[liberal, Kookoo]</td>\n      <td>2</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>77444</td>\n      <td>@USER @USER Oh noes! Tough shit.</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, @USER, Oh, noes, !, Tough, shit, .)</td>\n      <td>[oh, no, tough, shit]</td>\n      <td>4</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13223</th>\n      <td>63482</td>\n      <td>@USER is advocating for conduct within bounds ...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>GRP</td>\n      <td>(@USER, is, advocating, for, conduct, within, ...</td>\n      <td>[advocate, conduct, bound, Human, Rights, terr...</td>\n      <td>23</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13227</th>\n      <td>87416</td>\n      <td>@USER @USER @USER @USER Liars like the Antifa ...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>GRP</td>\n      <td>(@USER, @USER, @USER, @USER, Liars, like, the,...</td>\n      <td>[liar, like, Antifa, twin, vigorously, defend]</td>\n      <td>6</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13235</th>\n      <td>95338</td>\n      <td>@USER Sometimes I get strong vibes from people...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n      <td>(@USER, Sometimes, I, get, strong, vibes, from...</td>\n      <td>[strong, vibe, people, man, vibe, ten, million...</td>\n      <td>10</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13237</th>\n      <td>82921</td>\n      <td>@USER And why report this garbage.  We don't g...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>OTH</td>\n      <td>(@USER, And, why, report, this, garbage, .,  ,...</td>\n      <td>[report, garbage, crap]</td>\n      <td>3</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13238</th>\n      <td>27429</td>\n      <td>@USER Pussy</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n      <td>(@USER, Pussy)</td>\n      <td>[Pussy]</td>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>4400 rows  10 columns</p>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "id                                                           86426\ntweet            @USER She should ask a few native Americans wh...\nsubtask_a                                                      OFF\nsubtask_b                                                      UNT\nsubtask_c                                                      NaN\ntokens           (@USER, She, should, ask, a, few, native, Amer...\nlemmas                                    [ask, native, Americans]\nlength_lemmas                                                    3\nnumbers          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\nlabels_b                                                         1\nName: 0, dtype: object"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = tweets['labels_b'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1],\n        [0],\n        [1],\n        [0],\n        [1]], dtype=torch.int8)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = torch.cat((X_train, y_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Opracowywanie danych testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_lemmas = convert_words_to_numbers(test_b['lemmas'], dict_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['$',\n \"'cause\",\n \"'em\",\n '+',\n '-Antifa',\n '-Awkward',\n '-Bill',\n '-GOP',\n '-Human',\n '-I']"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict_lemmas)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# zamiana lematu na liczbe ze slownika ktory odpowiada danemu slowu\n",
    "test_b['numbers'] = test_b['lemmas'].apply(lambda row : lemmas_to_numbers(row, max_width, dict_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    [WhoIsQ, wherestheserver, DumpNike, DECLASFISA...\n1    [NoPasaran, unity, demo, oppose, far, right, L...\n2                                         [fuck, time]\n3                    [feeling, kiss, humiliate, later]\n4                               [Nigga, ware, da, hit]\nName: lemmas, dtype: object"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b['lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n5    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\nName: numbers, dtype: object"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b.loc[:5, 'numbers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Robienie tego samego procesu co wczeniej dla danych testowych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = test_b['numbers'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cat_cols = ['subtask_a', 'subtask_b', 'subtask_c']\n",
    "# for col in cat_cols:\n",
    "#     X_test[col] = X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_b['subtask_b'] = test_b['subtask_b'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_b['labels_b'] = test_b['subtask_b'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0      0\n1      0\n2      0\n3      0\n4      1\n      ..\n96     0\n97     0\n98     0\n99     0\n100    0\nName: labels_b, Length: 101, dtype: int8"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OFFENSIVE jest jako 1, a NOT OFFENSIVE jest jako 0\n",
    "test_b.loc[:100, 'labels_b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = test_b['labels_b'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = torch.tensor(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0],\n        [0],\n        [0],\n        [0],\n        [1]], dtype=torch.int8)"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_test_b = torch.cat((X_test, y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_test_b = data_test_b.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### sprawdzanie czy etykiety s tak samo przydzielone liczbom w danych testowych i treningowych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "  subtask_b  labels_b\n0       UNT         1\n1       TIN         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subtask_b</th>\n      <th>labels_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>UNT</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TIN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[[0,1], ['subtask_b', 'labels_b']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  subtask_b  labels_b\n0       TIN         0\n4       UNT         1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subtask_b</th>\n      <th>labels_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TIN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>UNT</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b.loc[[0,4], ['subtask_b', 'labels_b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generowanie embeding贸w na podstawie embeding贸w ze spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings.append(np.zeros(96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in dict_lemmas.items():\n",
    "    embeddings.append(nlp(key)[0].vector)\n",
    "    # print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "10528"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_lemmas_inverted = {v: k for k, v in dict_lemmas.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dict_lemmas_inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# sprawdzanie embedding贸w - czy si dobrze zapisay\n",
    "for key, value in dict_lemmas.items():\n",
    "    comparison = embeddings[value] == nlp(key)[0].vector\n",
    "    if comparison.all() == False:\n",
    "        print('false')\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.676073  ,  0.09062457, -0.19625556,  0.9512366 ,  0.7504209 ,\n        1.1548312 ,  1.0129769 , -0.8388504 , -1.1186899 ,  0.71350086],\n      dtype=float32)"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emb_torch = torch.tensor(embeddings, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10529, 96])"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_torch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, emb_vectors, in_features=18, h1=80, h2=50, h3=None, embedding_dim=None, out_features=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # warstwa embedding贸w wczytujca embeddingi przekazane przy tworzeniu modelu\n",
    "        self.embedding = nn.Embedding.from_pretrained(emb_vectors)\n",
    "\n",
    "        # self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # dropout layer - losowe pomijanie uczenia si pewnych neuron贸w\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_dim * in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        if h3 is None:\n",
    "            self.out = nn.Linear(h2, out_features)\n",
    "        # self.sig = nn.Sigmoid()\n",
    "        else:\n",
    "            self.fc3 = nn.Linear(h2, h3)\n",
    "            self.out = nn.Linear(h3, out_features)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = x.long()\n",
    "        # print(x.shape)\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        # print(embeds.shape)\n",
    "        embeds = embeds.view(embeds.shape[0], -1)\n",
    "        # print(embeds.shape)\n",
    "        x = torch.sigmoid(self.fc1(embeds))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        if h3 is not None:\n",
    "            x = torch.sigmoid(self.fc3(x))\n",
    "            x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ustawnia modelu i sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max width: 73\n"
     ]
    }
   ],
   "source": [
    "print('max width: 73')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.005\n",
    "batch_size = 500\n",
    "vocab_size = len(dict_lemmas) + 1\n",
    "embedding_dim = emb_torch.shape[1]\n",
    "h1 = 2\n",
    "h2 = 3\n",
    "h3 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "test_dataset_loader_b = torch.utils.data.DataLoader(data_test_b, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tworzenie instancji modelu\n",
    "Ustawianie funkcji straty i optymalizatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tworzenie numpy array z listy liczb (odpowiadajcych lematom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "40"
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "model = Model(emb_torch, max_width, h1, h2, h3, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Model(\n  (embedding): Embedding(10529, 96)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc1): Linear(in_features=3840, out_features=2, bias=True)\n  (fc2): Linear(in_features=2, out_features=3, bias=True)\n  (out): Linear(in_features=3, out_features=1, bias=True)\n)"
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ustawianie nauki sieci i samo uczenie si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "losses_test = []\n",
    "accuracy = []\n",
    "accuracy_test = []\n",
    "train_count = len(tweets)\n",
    "test_count_a = len(test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "save_every_epoch = int(epochs/10)\n",
    "losses_imp = []\n",
    "losses_test_imp = []\n",
    "accuracy_imp = []\n",
    "accuracy_test_imp = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on the first batch: 1.1654714345932007\n",
      "Loss on the first batch on test data: 1.0880898237228394\n",
      "torch.Size([])\n",
      " epoch: 0 | loss: 0.0022950558228926224 | predicted: 524 |accuracy: 11.909090995788574 | test loss: 0.004533707598845164 | predicted: 27 | test accuracy: 11.250000953674316\n",
      " epoch: 1 | loss: 0.0021441665562716397 | predicted: 524 |accuracy: 11.909090995788574 | test loss: 0.004212685426076253 | predicted: 27 | test accuracy: 11.250000953674316\n",
      " epoch: 2 | loss: 0.002012991254979914 | predicted: 524 |accuracy: 11.909090995788574 | test loss: 0.004009995112816493 | predicted: 27 | test accuracy: 11.250000953674316\n",
      " epoch: 3 | loss: 0.0018923618576743386 | predicted: 524 |accuracy: 11.909090995788574 | test loss: 0.00374000941713651 | predicted: 27 | test accuracy: 11.250000953674316\n",
      " epoch: 4 | loss: 0.001786248358813199 | predicted: 524 |accuracy: 11.909090995788574 | test loss: 0.0035497883955637613 | predicted: 27 | test accuracy: 11.250000953674316\n",
      " epoch: 5 | loss: 0.001686642820184881 | predicted: 524 |accuracy: 11.909090995788574 | test loss: 0.0033245104054609935 | predicted: 27 | test accuracy: 11.250000953674316\n",
      " epoch: 6 | loss: 0.0015954952890222722 | predicted: 524 |accuracy: 11.909090995788574 | test loss: 0.0031462162733078003 | predicted: 52 | test accuracy: 21.666667938232422\n",
      " epoch: 7 | loss: 0.0015103670683774082 | predicted: 1011 |accuracy: 22.977272033691406 | test loss: 0.0030035292108853656 | predicted: 50 | test accuracy: 20.83333396911621\n",
      " epoch: 8 | loss: 0.0014337778091430664 | predicted: 2124 |accuracy: 48.272727966308594 | test loss: 0.0027993351221084596 | predicted: 154 | test accuracy: 64.16667175292969\n",
      " epoch: 9 | loss: 0.0013581588051535867 | predicted: 3018 |accuracy: 68.59091186523438 | test loss: 0.0026688677569230396 | predicted: 196 | test accuracy: 81.66667175292969\n",
      " epoch: 10 | loss: 0.0012913105704567649 | predicted: 3580 |accuracy: 81.36363983154297 | test loss: 0.002545710156361262 | predicted: 197 | test accuracy: 82.08333587646484\n",
      " epoch: 11 | loss: 0.0012320471893657338 | predicted: 3643 |accuracy: 82.79545593261719 | test loss: 0.002422986924648285 | predicted: 201 | test accuracy: 83.75000762939453\n",
      " epoch: 12 | loss: 0.0011770448901436547 | predicted: 3778 |accuracy: 85.86363983154297 | test loss: 0.0023306104044119517 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 13 | loss: 0.0011314153671264648 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0021924952665964763 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 14 | loss: 0.0010826041481711648 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.002177656690279643 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 15 | loss: 0.0010406750982457941 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.002055918425321579 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 16 | loss: 0.0010097220810976896 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0020088423043489456 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 17 | loss: 0.0009727933190085671 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001953553408384323 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 18 | loss: 0.0009481546011838046 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001897295316060384 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 19 | loss: 0.0009221321886236018 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0018298727770646413 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 20 | loss: 0.0009020083058964122 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0018083829432725906 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 21 | loss: 0.0008805236491290006 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0017732756833235422 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 22 | loss: 0.0008706952225078236 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0017277785887320836 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 23 | loss: 0.0008615915883671153 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001701873540878296 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 24 | loss: 0.0008519436012614857 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001724933832883835 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 25 | loss: 0.0008398162234913219 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0017076919476191202 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 26 | loss: 0.0008366079763932661 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001720424989859263 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 27 | loss: 0.0008213813196529041 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0016199558973312377 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 28 | loss: 0.0008204470439390702 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0016563874979813895 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 29 | loss: 0.0008173311840404164 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001666725551088651 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 30 | loss: 0.0008074878020720048 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015647348016500473 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 31 | loss: 0.0008102379603819414 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0016277611255645752 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 32 | loss: 0.0008112501014362683 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0016222101946671804 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 33 | loss: 0.0007962418686259877 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015732002755006155 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 34 | loss: 0.0007922186634757302 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015797149389982224 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 35 | loss: 0.000798399340022694 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015515712400277456 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 36 | loss: 0.0007964609969745983 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015287650128205617 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 37 | loss: 0.0007894219593568281 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015636075288057328 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 38 | loss: 0.000790139761838046 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015309087932109833 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 39 | loss: 0.0007750804315913807 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0016329704473416011 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 40 | loss: 0.0007918831976977262 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015377034743626913 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 41 | loss: 0.0007712067257274281 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015623047947883606 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 42 | loss: 0.0007749708132310347 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015913637975851695 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 43 | loss: 0.0007746304165233266 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015229826172192891 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 44 | loss: 0.0007681344314055009 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001566346858938535 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 45 | loss: 0.0007584714889526368 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014902004351218542 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 46 | loss: 0.0007558739727193659 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015159728626410165 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 47 | loss: 0.0007564139366149903 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015324233720699946 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 48 | loss: 0.0007377636974508112 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015411620338757833 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 49 | loss: 0.0007466684688221325 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001474140708645185 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 50 | loss: 0.0007453916289589621 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015063649664322535 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 51 | loss: 0.0007410227168690074 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015342416862646738 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 52 | loss: 0.0007355163314125754 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001456453651189804 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 53 | loss: 0.0007383197004144842 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014535332719484964 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 54 | loss: 0.0007365589792078191 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015781654665867487 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 55 | loss: 0.0007317765734412453 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015446664144595464 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 56 | loss: 0.0007299528880552812 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015617173165082931 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 57 | loss: 0.0007273223183371804 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014665013800064723 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 58 | loss: 0.0007206804102117366 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015578204145034154 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 59 | loss: 0.0007293335416100242 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001418966179092725 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 60 | loss: 0.0007178096337751909 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001529701923330625 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 61 | loss: 0.0007210593873804266 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001497187465429306 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 62 | loss: 0.0007244528423656117 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015196514626344044 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 63 | loss: 0.0007202597639777444 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015317740539709727 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 64 | loss: 0.0007209699804132635 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015150738259156545 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 65 | loss: 0.0007184445316141302 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001528812696536382 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 66 | loss: 0.0007105250792069868 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015666066358486811 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 67 | loss: 0.0007083912329240279 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014558013528585434 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 68 | loss: 0.0007070666009729559 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015498384833335876 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 69 | loss: 0.000705424276265231 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001504230499267578 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 70 | loss: 0.0007249062169681896 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015058420598506928 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 71 | loss: 0.0007123314250599254 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015402520696322123 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 72 | loss: 0.0007123115929690275 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001478533074259758 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 73 | loss: 0.000698603174903176 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015574907263120016 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 74 | loss: 0.0007098300348628651 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014274369925260544 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 75 | loss: 0.0007146316224878485 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015803446372350057 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 76 | loss: 0.0006980543244968761 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014937584598859151 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 77 | loss: 0.0007142570885744962 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014995058377583821 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 78 | loss: 0.0007025406577370383 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001531850794951121 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 79 | loss: 0.0007127131115306507 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015903246899445851 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 80 | loss: 0.0007022737914865667 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015289048353830973 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 81 | loss: 0.0006942583214152943 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014400022725264232 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 82 | loss: 0.0007034305008974943 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001462907095750173 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 83 | loss: 0.0006895767016844316 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014301229268312455 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 84 | loss: 0.0007159965146671642 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001523135354121526 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 85 | loss: 0.0007064509391784668 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001597402368982633 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 86 | loss: 0.0007067802819338712 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015817597508430482 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 87 | loss: 0.0007003673098304055 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014778400460879009 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 88 | loss: 0.000703737735748291 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015243048469225566 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 89 | loss: 0.000689292387528853 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015127540876468022 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 90 | loss: 0.0006954409859397195 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015302265683809916 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 91 | loss: 0.0006983165849338878 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014731680353482564 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 92 | loss: 0.000700826265595176 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001563618580500285 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 93 | loss: 0.0007048841498114846 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001463213935494423 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 94 | loss: 0.0006992220336740667 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014955004056294758 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 95 | loss: 0.0007033180106769908 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015740994364023208 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 96 | loss: 0.000707831545309587 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001468908910950025 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 97 | loss: 0.0006954023512926969 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0015670090913772583 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 98 | loss: 0.0007007578828118064 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.001559401179353396 | predicted: 213 | test accuracy: 88.75000762939453\n",
      " epoch: 99 | loss: 0.0007041837952353738 | predicted: 3876 |accuracy: 88.09091186523438 | test loss: 0.0014535035938024522 | predicted: 213 | test accuracy: 88.75000762939453\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for e in range(epochs):\n",
    "    loss_epoch = torch.empty(0)\n",
    "    correct_epoch = 0\n",
    "\n",
    "    loss_epoch_test = np.empty(0)\n",
    "    correct_epoch_test = 0\n",
    "\n",
    "    for batch_num, batch in enumerate(train_dataset_loader):\n",
    "        X_train = batch[:,:-1]\n",
    "        y_train = batch[:,-1].reshape(-1,1)\n",
    "        y_pred = model.forward(X_train)\n",
    "\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        if (e == 0 and batch_num == 0):\n",
    "            print(f'Loss on the first batch: {loss}')\n",
    "\n",
    "        # print(loss.item())\n",
    "        loss_epoch = np.append(loss_epoch, loss.detach().cpu().numpy())\n",
    "        # losses.append(loss.item())\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        predicted = torch.round(y_pred)\n",
    "        # print(y_train)\n",
    "        predicted = (predicted == y_train).sum().cpu()\n",
    "        pred_cpu = predicted.cpu()\n",
    "        # print(f'pred_cpu: {pred_cpu}')\n",
    "        correct_epoch += predicted\n",
    "\n",
    "# przechodzenie przez dane testowe\n",
    "    with torch.no_grad():\n",
    "        for batch_num_test, batch_test in enumerate(test_dataset_loader_b):\n",
    "            X_test = batch_test[:,:-1]\n",
    "            y_test = batch_test[:,-1].reshape(-1,1)\n",
    "            y_pred_test = model.forward(X_test)\n",
    "\n",
    "            loss_test = criterion(y_pred_test, y_test)\n",
    "            if (e == 0 and batch_num_test == 0):\n",
    "                print(f'Loss on the first batch on test data: {loss_test}')\n",
    "                print(loss_test.shape)\n",
    "\n",
    "            # print(loss.item())\n",
    "            loss_epoch_test = np.append(loss_epoch_test, loss_test.item())\n",
    "            # print(loss_test)\n",
    "            # losses.append(loss.item())\n",
    "\n",
    "            predicted = torch.round(y_pred_test)\n",
    "            # print(predicted)\n",
    "            # print(y_test)\n",
    "            predicted = (predicted == y_test).sum()\n",
    "            pred_cpu = predicted.cpu()\n",
    "            # print(f'pred_cpu: {pred_cpu}')\n",
    "            correct_epoch_test += predicted\n",
    "\n",
    "        loss_epoch_test = loss_epoch_test.sum() / test_count_a\n",
    "        losses_test.append(loss_epoch_test)\n",
    "        accuracy_epoch_test = correct_epoch_test * 100/test_count_a\n",
    "        accuracy_epoch_test_cpu = accuracy_epoch_test.cpu()\n",
    "        accuracy_test.append(accuracy_epoch_test_cpu)\n",
    "\n",
    "        if e % save_every_epoch == 0:\n",
    "            losses_test_imp.append((e, loss_epoch_test))\n",
    "            accuracy_test_imp.append((e, accuracy_epoch_test_cpu))\n",
    "\n",
    "    loss_epoch = loss_epoch.sum() / train_count\n",
    "    losses.append(loss_epoch)\n",
    "    accuracy_epoch = correct_epoch * 100/train_count\n",
    "    accuracy_epoch_cpu = accuracy_epoch.cpu()\n",
    "    accuracy.append(accuracy_epoch)\n",
    "\n",
    "    if e % save_every_epoch == 0:\n",
    "        losses_imp.append((e, loss_epoch))\n",
    "        accuracy_imp.append((e, accuracy_epoch_cpu))\n",
    "\n",
    "\n",
    "    # print(f'Test accuracy: {correct_epoch.item()}/{train_count} = {correct.item() * 100 / (test_count):7.3f}%')\n",
    "    print(f' epoch: {e} | loss: {loss_epoch} | predicted: {correct_epoch} |' \\\n",
    "            + f'accuracy: {accuracy_epoch} | test loss: {loss_epoch_test} | ' \\\n",
    "            + f'predicted: {correct_epoch_test} | test accuracy: {accuracy_epoch_test}')\n",
    "\n",
    "duration = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rysowanie funkcji straty i accuracy na przestrzeni epok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1152x504 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot loss functions over epochs\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,7))\n",
    "\n",
    "\n",
    "ax1.plot(range(epochs), losses, c='r')\n",
    "ax1.plot(range(epochs), losses_test)\n",
    "ax1.set_title('Losses and epochs')\n",
    "\n",
    "ax2.plot(range(epochs), accuracy, c='r')\n",
    "ax2.plot(range(epochs), accuracy_test)\n",
    "ax2.set_title(\"Accuracy and epochs\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dictionary storing the data\n",
    "summary = {\n",
    "    \"Best\": [min(losses), max(accuracy), min(losses_test), max(accuracy_test)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "for i in range(len(losses_imp)):\n",
    "    tr = 'Training ', losses_imp[i][0]\n",
    "    tt = 'Testing ', losses_test_imp[i][0]\n",
    "    summary[losses_imp[i][0]] = [losses_imp[i][1], accuracy_imp[i][1], losses_test_imp[i][1], accuracy_test_imp[i][1]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "# dataframe from dict\n",
    "summary_df = pd.DataFrame.from_dict(summary, orient='index', columns=['Loss', 'Accuracy', 'Loss test', 'Accuracy test'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy embeddings\n",
      "Model(\n",
      "  (embedding): Embedding(10529, 96)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=3840, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (out): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "learning_rate:  0.005\n",
      "batch_size:  500\n",
      "time:  3.2288827896118164\n"
     ]
    }
   ],
   "source": [
    "print('Spacy embeddings')\n",
    "print(model)\n",
    "print('learning_rate: ', learning_rate)\n",
    "print('batch_size: ', batch_size)\n",
    "print('time: ', duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          Loss         Accuracy  Loss test    Accuracy test\nBest  0.000689  tensor(88.0909)   0.001419  tensor(88.7500)\n0     0.002295  tensor(11.9091)   0.004534  tensor(11.2500)\n10    0.001291  tensor(81.3636)   0.002546  tensor(82.0833)\n20    0.000902  tensor(88.0909)   0.001808  tensor(88.7500)\n30    0.000807  tensor(88.0909)   0.001565  tensor(88.7500)\n40    0.000792  tensor(88.0909)   0.001538  tensor(88.7500)\n50    0.000745  tensor(88.0909)   0.001506  tensor(88.7500)\n60    0.000718  tensor(88.0909)   0.001530  tensor(88.7500)\n70    0.000725  tensor(88.0909)   0.001506  tensor(88.7500)\n80    0.000702  tensor(88.0909)   0.001529  tensor(88.7500)\n90    0.000695  tensor(88.0909)   0.001530  tensor(88.7500)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n      <th>Loss test</th>\n      <th>Accuracy test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Best</th>\n      <td>0.000689</td>\n      <td>tensor(88.0909)</td>\n      <td>0.001419</td>\n      <td>tensor(88.7500)</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.002295</td>\n      <td>tensor(11.9091)</td>\n      <td>0.004534</td>\n      <td>tensor(11.2500)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.001291</td>\n      <td>tensor(81.3636)</td>\n      <td>0.002546</td>\n      <td>tensor(82.0833)</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.000902</td>\n      <td>tensor(88.0909)</td>\n      <td>0.001808</td>\n      <td>tensor(88.7500)</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.000807</td>\n      <td>tensor(88.0909)</td>\n      <td>0.001565</td>\n      <td>tensor(88.7500)</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.000792</td>\n      <td>tensor(88.0909)</td>\n      <td>0.001538</td>\n      <td>tensor(88.7500)</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>0.000745</td>\n      <td>tensor(88.0909)</td>\n      <td>0.001506</td>\n      <td>tensor(88.7500)</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>0.000718</td>\n      <td>tensor(88.0909)</td>\n      <td>0.001530</td>\n      <td>tensor(88.7500)</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.000725</td>\n      <td>tensor(88.0909)</td>\n      <td>0.001506</td>\n      <td>tensor(88.7500)</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>0.000702</td>\n      <td>tensor(88.0909)</td>\n      <td>0.001529</td>\n      <td>tensor(88.7500)</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>0.000695</td>\n      <td>tensor(88.0909)</td>\n      <td>0.001530</td>\n      <td>tensor(88.7500)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cuda",
   "language": "python",
   "name": "torch-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}